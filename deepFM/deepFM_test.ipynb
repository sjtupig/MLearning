{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepFM import DeepFM\n",
    "from mxnet.gluon import nn\n",
    "from mxnet import nd, autograd\n",
    "import mxnet as mx\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 准备数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = np.random.randint(0,500, size = (100000,1))\n",
    "x2 = np.random.randint(0,1000, size = (100000,1))\n",
    "x3 = np.random.randint(0,2, size = (100000,1))\n",
    "x4 = np.random.randn(100000,1)\n",
    "X = nd.array(np.concatenate((x1,x2,x3,x4), axis = 1))\n",
    "X_onehot1 = nd.one_hot(X[:,0],depth = int(nd.max(X[:,0]).asscalar()+1))\n",
    "X_onehot2 = nd.one_hot(X[:,1],depth = int(nd.max(X[:,1]).asscalar()+1))\n",
    "X_onehot3 = nd.one_hot(X[:,2],depth = int(nd.max(X[:,2]).asscalar()+1))\n",
    "X = nd.concat(X_onehot1,X_onehot2,X_onehot3, X[:,3].reshape(-1,1),dim = 1)\n",
    "\n",
    "y = nd.random.shuffle(nd.concat(nd.ones((1000,1)), nd.zeros((99000,1)), dim = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 1503)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "deepFM = DeepFM(n_features = 1503, f = 5, field_num = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "deepFM.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = deepFM.predict_prob(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49313451515151513"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y.asnumpy(), y_predict.asnumpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "deepfm0_ (\n",
       "  Parameter deepfm0_latent_vec (shape=(1503, 5), dtype=<class 'numpy.float32'>)\n",
       "  Parameter deepfm0_w (shape=(1503, 1), dtype=<class 'numpy.float32'>)\n",
       "  Parameter deepfm0_b (shape=(1, 1), dtype=<class 'numpy.float32'>)\n",
       "  Parameter dense0_weight (shape=(200, 20), dtype=float32)\n",
       "  Parameter dense0_bias (shape=(200,), dtype=float32)\n",
       "  Parameter dense1_weight (shape=(200, 200), dtype=float32)\n",
       "  Parameter dense1_bias (shape=(200,), dtype=float32)\n",
       "  Parameter dense2_weight (shape=(1, 200), dtype=float32)\n",
       "  Parameter dense2_bias (shape=(1,), dtype=float32)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deepFM.collect_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[ 0.0068339   0.01299825  0.0301265   0.04819721  0.01438687]\n",
       " [ 0.05011239  0.00628365  0.04861524 -0.01068833  0.01729892]\n",
       " [ 0.02042518 -0.01618656 -0.00873779 -0.02834515  0.05484822]\n",
       " ...\n",
       " [-0.06364369 -0.00241996  0.03635876  0.02910428 -0.05770696]\n",
       " [ 0.0658746  -0.05029523  0.01848106  0.02461895  0.06895965]\n",
       " [ 0.06530461  0.05058237  0.04452907  0.01059669  0.05580745]]\n",
       "<NDArray 1503x5 @cpu(0)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deepFM.collect_params()['deepfm0_latent_vec'].data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[-0.00613896]\n",
       " [-0.03968295]\n",
       " [ 0.00958075]\n",
       " ...\n",
       " [ 0.06593788]\n",
       " [-0.04934957]\n",
       " [-0.01224296]]\n",
       "<NDArray 1503x1 @cpu(0)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deepFM.collect_params()['deepfm0_w'].data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[0.03896836]]\n",
       "<NDArray 1x1 @cpu(0)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deepFM.collect_params()['deepfm0_b'].data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[-0.04247847  0.06293995 -0.01837847 ... -0.06219994  0.01467837\n",
       "  -0.00683771]\n",
       " [ 0.0334969  -0.06720173 -0.06451371 ... -0.0396449   0.0269461\n",
       "   0.00912645]\n",
       " [ 0.0093242   0.05111437 -0.03284547 ...  0.02060438  0.03028581\n",
       "   0.04779406]\n",
       " ...\n",
       " [-0.06855166  0.05331292  0.03759063 ...  0.0586691  -0.04376023\n",
       "   0.04661175]\n",
       " [-0.05061454 -0.02160443 -0.02231426 ...  0.06688141  0.06003698\n",
       "  -0.0442403 ]\n",
       " [ 0.0166986  -0.01789841 -0.03207165 ... -0.05084866  0.0428737\n",
       "  -0.028384  ]]\n",
       "<NDArray 200x20 @cpu(0)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deepFM.collect_params()['dense0_weight'].data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
       " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
       " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
       " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
       " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
       " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
       " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
       " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
       " 0. 0. 0. 0. 0. 0. 0. 0.]\n",
       "<NDArray 200 @cpu(0)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deepFM.collect_params()['dense0_bias'].data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 iter: loss is: \n",
      "[0.45802754]\n",
      "<NDArray 1 @cpu(0)> loss reduction is: \n",
      "[0.2587399]\n",
      "<NDArray 1 @cpu(0)>\n",
      "2 iter: loss is: \n",
      "[0.35046375]\n",
      "<NDArray 1 @cpu(0)> loss reduction is: \n",
      "[0.10756379]\n",
      "<NDArray 1 @cpu(0)>\n",
      "3 iter: loss is: \n",
      "[0.28638947]\n",
      "<NDArray 1 @cpu(0)> loss reduction is: \n",
      "[0.06407428]\n",
      "<NDArray 1 @cpu(0)>\n",
      "4 iter: loss is: \n",
      "[0.24366297]\n",
      "<NDArray 1 @cpu(0)> loss reduction is: \n",
      "[0.0427265]\n",
      "<NDArray 1 @cpu(0)>\n",
      "5 iter: loss is: \n",
      "[0.21318641]\n",
      "<NDArray 1 @cpu(0)> loss reduction is: \n",
      "[0.03047656]\n",
      "<NDArray 1 @cpu(0)>\n",
      "6 iter: loss is: \n",
      "[0.19040512]\n",
      "<NDArray 1 @cpu(0)> loss reduction is: \n",
      "[0.0227813]\n",
      "<NDArray 1 @cpu(0)>\n",
      "7 iter: loss is: \n",
      "[0.17276779]\n",
      "<NDArray 1 @cpu(0)> loss reduction is: \n",
      "[0.01763733]\n",
      "<NDArray 1 @cpu(0)>\n",
      "8 iter: loss is: \n",
      "[0.15874]\n",
      "<NDArray 1 @cpu(0)> loss reduction is: \n",
      "[0.01402779]\n",
      "<NDArray 1 @cpu(0)>\n",
      "9 iter: loss is: \n",
      "[0.14733823]\n",
      "<NDArray 1 @cpu(0)> loss reduction is: \n",
      "[0.01140177]\n",
      "<NDArray 1 @cpu(0)>\n",
      "10 iter: loss is: \n",
      "[0.13790663]\n",
      "<NDArray 1 @cpu(0)> loss reduction is: \n",
      "[0.0094316]\n",
      "<NDArray 1 @cpu(0)>\n",
      "11 iter: loss is: \n",
      "[0.12998512]\n",
      "<NDArray 1 @cpu(0)> loss reduction is: \n",
      "[0.0079215]\n",
      "<NDArray 1 @cpu(0)>\n",
      "12 iter: loss is: \n",
      "[0.1232501]\n",
      "<NDArray 1 @cpu(0)> loss reduction is: \n",
      "[0.00673502]\n",
      "<NDArray 1 @cpu(0)>\n",
      "13 iter: loss is: \n",
      "[0.11746097]\n",
      "<NDArray 1 @cpu(0)> loss reduction is: \n",
      "[0.00578914]\n",
      "<NDArray 1 @cpu(0)>\n",
      "14 iter: loss is: \n",
      "[0.11243607]\n",
      "<NDArray 1 @cpu(0)> loss reduction is: \n",
      "[0.0050249]\n",
      "<NDArray 1 @cpu(0)>\n",
      "15 iter: loss is: \n",
      "[0.10804071]\n",
      "<NDArray 1 @cpu(0)> loss reduction is: \n",
      "[0.00439536]\n",
      "<NDArray 1 @cpu(0)>\n",
      "16 iter: loss is: \n",
      "[0.10416711]\n",
      "<NDArray 1 @cpu(0)> loss reduction is: \n",
      "[0.0038736]\n",
      "<NDArray 1 @cpu(0)>\n",
      "17 iter: loss is: \n",
      "[0.10073088]\n",
      "<NDArray 1 @cpu(0)> loss reduction is: \n",
      "[0.00343623]\n",
      "<NDArray 1 @cpu(0)>\n",
      "18 iter: loss is: \n",
      "[0.09766532]\n",
      "<NDArray 1 @cpu(0)> loss reduction is: \n",
      "[0.00306556]\n",
      "<NDArray 1 @cpu(0)>\n",
      "19 iter: loss is: \n",
      "[0.09491608]\n",
      "<NDArray 1 @cpu(0)> loss reduction is: \n",
      "[0.00274925]\n",
      "<NDArray 1 @cpu(0)>\n",
      "20 iter: loss is: \n",
      "[0.0924378]\n",
      "<NDArray 1 @cpu(0)> loss reduction is: \n",
      "[0.00247827]\n",
      "<NDArray 1 @cpu(0)>\n",
      "21 iter: loss is: \n",
      "[0.09019492]\n",
      "<NDArray 1 @cpu(0)> loss reduction is: \n",
      "[0.00224289]\n",
      "<NDArray 1 @cpu(0)>\n",
      "22 iter: loss is: \n",
      "[0.0881568]\n",
      "<NDArray 1 @cpu(0)> loss reduction is: \n",
      "[0.00203811]\n",
      "<NDArray 1 @cpu(0)>\n",
      "23 iter: loss is: \n",
      "[0.08629818]\n",
      "<NDArray 1 @cpu(0)> loss reduction is: \n",
      "[0.00185863]\n",
      "<NDArray 1 @cpu(0)>\n",
      "24 iter: loss is: \n",
      "[0.0845975]\n",
      "<NDArray 1 @cpu(0)> loss reduction is: \n",
      "[0.00170068]\n",
      "<NDArray 1 @cpu(0)>\n",
      "25 iter: loss is: \n",
      "[0.08303644]\n",
      "<NDArray 1 @cpu(0)> loss reduction is: \n",
      "[0.00156106]\n",
      "<NDArray 1 @cpu(0)>\n",
      "26 iter: loss is: \n",
      "[0.08159962]\n",
      "<NDArray 1 @cpu(0)> loss reduction is: \n",
      "[0.00143682]\n",
      "<NDArray 1 @cpu(0)>\n",
      "27 iter: loss is: \n",
      "[0.08027356]\n",
      "<NDArray 1 @cpu(0)> loss reduction is: \n",
      "[0.00132605]\n",
      "<NDArray 1 @cpu(0)>\n",
      "28 iter: loss is: \n",
      "[0.0790467]\n",
      "<NDArray 1 @cpu(0)> loss reduction is: \n",
      "[0.00122686]\n",
      "<NDArray 1 @cpu(0)>\n",
      "29 iter: loss is: \n",
      "[0.07790907]\n",
      "<NDArray 1 @cpu(0)> loss reduction is: \n",
      "[0.00113763]\n",
      "<NDArray 1 @cpu(0)>\n",
      "30 iter: loss is: \n",
      "[0.07685169]\n",
      "<NDArray 1 @cpu(0)> loss reduction is: \n",
      "[0.00105738]\n",
      "<NDArray 1 @cpu(0)>\n",
      "31 iter: loss is: \n",
      "[0.07586715]\n",
      "<NDArray 1 @cpu(0)> loss reduction is: \n",
      "[0.00098454]\n",
      "<NDArray 1 @cpu(0)>\n",
      "32 iter: loss is: \n",
      "[0.07494848]\n",
      "<NDArray 1 @cpu(0)> loss reduction is: \n",
      "[0.00091866]\n",
      "<NDArray 1 @cpu(0)>\n",
      "33 iter: loss is: \n",
      "[0.07408974]\n",
      "<NDArray 1 @cpu(0)> loss reduction is: \n",
      "[0.00085874]\n",
      "<NDArray 1 @cpu(0)>\n",
      "34 iter: loss is: \n",
      "[0.07328589]\n",
      "<NDArray 1 @cpu(0)> loss reduction is: \n",
      "[0.00080386]\n",
      "<NDArray 1 @cpu(0)>\n",
      "35 iter: loss is: \n",
      "[0.0725321]\n",
      "<NDArray 1 @cpu(0)> loss reduction is: \n",
      "[0.00075378]\n",
      "<NDArray 1 @cpu(0)>\n",
      "36 iter: loss is: \n",
      "[0.07182418]\n",
      "<NDArray 1 @cpu(0)> loss reduction is: \n",
      "[0.00070792]\n",
      "<NDArray 1 @cpu(0)>\n",
      "37 iter: loss is: \n",
      "[0.07115854]\n",
      "<NDArray 1 @cpu(0)> loss reduction is: \n",
      "[0.00066564]\n",
      "<NDArray 1 @cpu(0)>\n",
      "38 iter: loss is: \n",
      "[0.07053168]\n",
      "<NDArray 1 @cpu(0)> loss reduction is: \n",
      "[0.00062685]\n",
      "<NDArray 1 @cpu(0)>\n",
      "39 iter: loss is: \n",
      "[0.0699406]\n",
      "<NDArray 1 @cpu(0)> loss reduction is: \n",
      "[0.00059108]\n",
      "<NDArray 1 @cpu(0)>\n",
      "40 iter: loss is: \n",
      "[0.06938239]\n",
      "<NDArray 1 @cpu(0)> loss reduction is: \n",
      "[0.00055821]\n",
      "<NDArray 1 @cpu(0)>\n",
      "41 iter: loss is: \n",
      "[0.06885487]\n",
      "<NDArray 1 @cpu(0)> loss reduction is: \n",
      "[0.00052752]\n",
      "<NDArray 1 @cpu(0)>\n",
      "42 iter: loss is: \n",
      "[0.06835567]\n",
      "<NDArray 1 @cpu(0)> loss reduction is: \n",
      "[0.0004992]\n",
      "<NDArray 1 @cpu(0)>\n",
      "43 iter: loss is: \n",
      "[0.06788279]\n",
      "<NDArray 1 @cpu(0)> loss reduction is: \n",
      "[0.00047288]\n",
      "<NDArray 1 @cpu(0)>\n",
      "44 iter: loss is: \n",
      "[0.06743442]\n",
      "<NDArray 1 @cpu(0)> loss reduction is: \n",
      "[0.00044837]\n",
      "<NDArray 1 @cpu(0)>\n",
      "45 iter: loss is: \n",
      "[0.06700885]\n",
      "<NDArray 1 @cpu(0)> loss reduction is: \n",
      "[0.00042558]\n",
      "<NDArray 1 @cpu(0)>\n",
      "46 iter: loss is: \n",
      "[0.06660462]\n",
      "<NDArray 1 @cpu(0)> loss reduction is: \n",
      "[0.00040422]\n",
      "<NDArray 1 @cpu(0)>\n",
      "47 iter: loss is: \n",
      "[0.06622026]\n",
      "<NDArray 1 @cpu(0)> loss reduction is: \n",
      "[0.00038436]\n",
      "<NDArray 1 @cpu(0)>\n",
      "48 iter: loss is: \n",
      "[0.06585444]\n",
      "<NDArray 1 @cpu(0)> loss reduction is: \n",
      "[0.00036582]\n",
      "<NDArray 1 @cpu(0)>\n",
      "49 iter: loss is: \n",
      "[0.065506]\n",
      "<NDArray 1 @cpu(0)> loss reduction is: \n",
      "[0.00034843]\n",
      "<NDArray 1 @cpu(0)>\n",
      "50 iter: loss is: \n",
      "[0.06517391]\n",
      "<NDArray 1 @cpu(0)> loss reduction is: \n",
      "[0.00033209]\n",
      "<NDArray 1 @cpu(0)>\n",
      "51 iter: loss is: \n",
      "[0.06485713]\n",
      "<NDArray 1 @cpu(0)> loss reduction is: \n",
      "[0.00031678]\n",
      "<NDArray 1 @cpu(0)>\n",
      "52 iter: loss is: \n",
      "[0.06455472]\n",
      "<NDArray 1 @cpu(0)> loss reduction is: \n",
      "[0.0003024]\n",
      "<NDArray 1 @cpu(0)>\n",
      "53 iter: loss is: \n",
      "[0.06426586]\n",
      "<NDArray 1 @cpu(0)> loss reduction is: \n",
      "[0.00028886]\n",
      "<NDArray 1 @cpu(0)>\n",
      "54 iter: loss is: \n",
      "[0.06398969]\n",
      "<NDArray 1 @cpu(0)> loss reduction is: \n",
      "[0.00027617]\n",
      "<NDArray 1 @cpu(0)>\n",
      "55 iter: loss is: \n",
      "[0.06372558]\n",
      "<NDArray 1 @cpu(0)> loss reduction is: \n",
      "[0.00026412]\n",
      "<NDArray 1 @cpu(0)>\n",
      "56 iter: loss is: \n",
      "[0.06347279]\n",
      "<NDArray 1 @cpu(0)> loss reduction is: \n",
      "[0.00025279]\n",
      "<NDArray 1 @cpu(0)>\n",
      "57 iter: loss is: \n",
      "[0.0632307]\n",
      "<NDArray 1 @cpu(0)> loss reduction is: \n",
      "[0.00024208]\n",
      "<NDArray 1 @cpu(0)>\n",
      "58 iter: loss is: \n",
      "[0.0629987]\n",
      "<NDArray 1 @cpu(0)> loss reduction is: \n",
      "[0.000232]\n",
      "<NDArray 1 @cpu(0)>\n",
      "59 iter: loss is: \n",
      "[0.06277631]\n",
      "<NDArray 1 @cpu(0)> loss reduction is: \n",
      "[0.00022239]\n",
      "<NDArray 1 @cpu(0)>\n",
      "60 iter: loss is: \n",
      "[0.06256293]\n",
      "<NDArray 1 @cpu(0)> loss reduction is: \n",
      "[0.00021338]\n",
      "<NDArray 1 @cpu(0)>\n",
      "61 iter: loss is: \n",
      "[0.06235816]\n",
      "<NDArray 1 @cpu(0)> loss reduction is: \n",
      "[0.00020477]\n",
      "<NDArray 1 @cpu(0)>\n",
      "62 iter: loss is: \n",
      "[0.06216155]\n",
      "<NDArray 1 @cpu(0)> loss reduction is: \n",
      "[0.00019661]\n",
      "<NDArray 1 @cpu(0)>\n",
      "63 iter: loss is: \n",
      "[0.06197264]\n",
      "<NDArray 1 @cpu(0)> loss reduction is: \n",
      "[0.00018892]\n",
      "<NDArray 1 @cpu(0)>\n",
      "64 iter: loss is: \n",
      "[0.06179108]\n",
      "<NDArray 1 @cpu(0)> loss reduction is: \n",
      "[0.00018156]\n",
      "<NDArray 1 @cpu(0)>\n",
      "65 iter: loss is: \n",
      "[0.06161647]\n",
      "<NDArray 1 @cpu(0)> loss reduction is: \n",
      "[0.00017461]\n",
      "<NDArray 1 @cpu(0)>\n",
      "66 iter: loss is: \n",
      "[0.0614485]\n",
      "<NDArray 1 @cpu(0)> loss reduction is: \n",
      "[0.00016797]\n",
      "<NDArray 1 @cpu(0)>\n",
      "67 iter: loss is: \n",
      "[0.06128683]\n",
      "<NDArray 1 @cpu(0)> loss reduction is: \n",
      "[0.00016167]\n",
      "<NDArray 1 @cpu(0)>\n",
      "68 iter: loss is: \n",
      "[0.06113117]\n",
      "<NDArray 1 @cpu(0)> loss reduction is: \n",
      "[0.00015566]\n",
      "<NDArray 1 @cpu(0)>\n",
      "69 iter: loss is: \n",
      "[0.06098122]\n",
      "<NDArray 1 @cpu(0)> loss reduction is: \n",
      "[0.00014995]\n",
      "<NDArray 1 @cpu(0)>\n",
      "70 iter: loss is: \n",
      "[0.06083668]\n",
      "<NDArray 1 @cpu(0)> loss reduction is: \n",
      "[0.00014454]\n",
      "<NDArray 1 @cpu(0)>\n",
      "71 iter: loss is: \n",
      "[0.06069741]\n",
      "<NDArray 1 @cpu(0)> loss reduction is: \n",
      "[0.00013928]\n",
      "<NDArray 1 @cpu(0)>\n",
      "72 iter: loss is: \n",
      "[0.06056307]\n",
      "<NDArray 1 @cpu(0)> loss reduction is: \n",
      "[0.00013433]\n",
      "<NDArray 1 @cpu(0)>\n",
      "73 iter: loss is: \n",
      "[0.06043346]\n",
      "<NDArray 1 @cpu(0)> loss reduction is: \n",
      "[0.00012961]\n",
      "<NDArray 1 @cpu(0)>\n",
      "74 iter: loss is: \n",
      "[0.0603084]\n",
      "<NDArray 1 @cpu(0)> loss reduction is: \n",
      "[0.00012507]\n",
      "<NDArray 1 @cpu(0)>\n",
      "75 iter: loss is: \n",
      "[0.06018765]\n",
      "<NDArray 1 @cpu(0)> loss reduction is: \n",
      "[0.00012074]\n",
      "<NDArray 1 @cpu(0)>\n",
      "76 iter: loss is: \n",
      "[0.06007105]\n",
      "<NDArray 1 @cpu(0)> loss reduction is: \n",
      "[0.0001166]\n",
      "<NDArray 1 @cpu(0)>\n",
      "77 iter: loss is: \n",
      "[0.05995842]\n",
      "<NDArray 1 @cpu(0)> loss reduction is: \n",
      "[0.00011264]\n",
      "<NDArray 1 @cpu(0)>\n",
      "78 iter: loss is: \n",
      "[0.05984959]\n",
      "<NDArray 1 @cpu(0)> loss reduction is: \n",
      "[0.00010883]\n",
      "<NDArray 1 @cpu(0)>\n",
      "79 iter: loss is: \n",
      "[0.05974435]\n",
      "<NDArray 1 @cpu(0)> loss reduction is: \n",
      "[0.00010523]\n",
      "<NDArray 1 @cpu(0)>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80 iter: loss is: \n",
      "[0.05964261]\n",
      "<NDArray 1 @cpu(0)> loss reduction is: \n",
      "[0.00010175]\n",
      "<NDArray 1 @cpu(0)>\n",
      "81 iter: loss is: \n",
      "[0.05954418]\n",
      "<NDArray 1 @cpu(0)> loss reduction is: \n",
      "[9.8433346e-05]\n",
      "<NDArray 1 @cpu(0)>\n",
      "82 iter: loss is: \n",
      "[0.05944897]\n",
      "<NDArray 1 @cpu(0)> loss reduction is: \n",
      "[9.5207244e-05]\n",
      "<NDArray 1 @cpu(0)>\n",
      "83 iter: loss is: \n",
      "[0.05935684]\n",
      "<NDArray 1 @cpu(0)> loss reduction is: \n",
      "[9.212643e-05]\n",
      "<NDArray 1 @cpu(0)>\n",
      "84 iter: loss is: \n",
      "[0.05926765]\n",
      "<NDArray 1 @cpu(0)> loss reduction is: \n",
      "[8.9194626e-05]\n",
      "<NDArray 1 @cpu(0)>\n",
      "85 iter: loss is: \n",
      "[0.0591813]\n",
      "<NDArray 1 @cpu(0)> loss reduction is: \n",
      "[8.635223e-05]\n",
      "<NDArray 1 @cpu(0)>\n",
      "86 iter: loss is: \n",
      "[0.05909765]\n",
      "<NDArray 1 @cpu(0)> loss reduction is: \n",
      "[8.364767e-05]\n",
      "<NDArray 1 @cpu(0)>\n",
      "87 iter: loss is: \n",
      "[0.05901663]\n",
      "<NDArray 1 @cpu(0)> loss reduction is: \n",
      "[8.101761e-05]\n",
      "<NDArray 1 @cpu(0)>\n",
      "88 iter: loss is: \n",
      "[0.05893812]\n",
      "<NDArray 1 @cpu(0)> loss reduction is: \n",
      "[7.851422e-05]\n",
      "<NDArray 1 @cpu(0)>\n",
      "89 iter: loss is: \n",
      "[0.058862]\n",
      "<NDArray 1 @cpu(0)> loss reduction is: \n",
      "[7.611513e-05]\n",
      "<NDArray 1 @cpu(0)>\n",
      "90 iter: loss is: \n",
      "[0.05878822]\n",
      "<NDArray 1 @cpu(0)> loss reduction is: \n",
      "[7.3779374e-05]\n",
      "<NDArray 1 @cpu(0)>\n",
      "91 iter: loss is: \n",
      "[0.05871668]\n",
      "<NDArray 1 @cpu(0)> loss reduction is: \n",
      "[7.153675e-05]\n",
      "<NDArray 1 @cpu(0)>\n",
      "92 iter: loss is: \n",
      "[0.05864729]\n",
      "<NDArray 1 @cpu(0)> loss reduction is: \n",
      "[6.939471e-05]\n",
      "<NDArray 1 @cpu(0)>\n",
      "93 iter: loss is: \n",
      "[0.05857999]\n",
      "<NDArray 1 @cpu(0)> loss reduction is: \n",
      "[6.7301095e-05]\n",
      "<NDArray 1 @cpu(0)>\n",
      "94 iter: loss is: \n",
      "[0.05851467]\n",
      "<NDArray 1 @cpu(0)> loss reduction is: \n",
      "[6.531924e-05]\n",
      "<NDArray 1 @cpu(0)>\n",
      "95 iter: loss is: \n",
      "[0.05845128]\n",
      "<NDArray 1 @cpu(0)> loss reduction is: \n",
      "[6.3393265e-05]\n",
      "<NDArray 1 @cpu(0)>\n",
      "96 iter: loss is: \n",
      "[0.05838975]\n",
      "<NDArray 1 @cpu(0)> loss reduction is: \n",
      "[6.1526895e-05]\n",
      "<NDArray 1 @cpu(0)>\n",
      "97 iter: loss is: \n",
      "[0.05833001]\n",
      "<NDArray 1 @cpu(0)> loss reduction is: \n",
      "[5.973503e-05]\n",
      "<NDArray 1 @cpu(0)>\n",
      "98 iter: loss is: \n",
      "[0.05827201]\n",
      "<NDArray 1 @cpu(0)> loss reduction is: \n",
      "[5.800277e-05]\n",
      "<NDArray 1 @cpu(0)>\n",
      "99 iter: loss is: \n",
      "[0.05821567]\n",
      "<NDArray 1 @cpu(0)> loss reduction is: \n",
      "[5.6337565e-05]\n",
      "<NDArray 1 @cpu(0)>\n",
      "100 iter: loss is: \n",
      "[0.05816092]\n",
      "<NDArray 1 @cpu(0)> loss reduction is: \n",
      "[5.475059e-05]\n",
      "<NDArray 1 @cpu(0)>\n"
     ]
    }
   ],
   "source": [
    "deepFM.train(X, y, max_iter = 100, batchsize = 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = deepFM.predict_prob(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.540634702020202"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y.asnumpy(), y_predict.asnumpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[-0. -0.  0.  0. -0.]\n",
       " [ 0. -0.  0.  0.  0.]\n",
       " [ 0. -0.  0.  0.  0.]\n",
       " ...\n",
       " [-0.  0. -0.  0.  0.]\n",
       " [-0.  0. -0.  0. -0.]\n",
       " [ 0. -0. -0.  0. -0.]]\n",
       "<NDArray 1503x5 @cpu(0)>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deepFM.collect_params()['deepfm0_latent_vec'].data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[-0.00884028]\n",
       " [-0.00743944]\n",
       " [-0.00949604]\n",
       " ...\n",
       " [-1.0749024 ]\n",
       " [-1.0844254 ]\n",
       " [ 0.02083395]]\n",
       "<NDArray 1503x1 @cpu(0)>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deepFM.collect_params()['deepfm0_w'].data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[-1.440484]]\n",
       "<NDArray 1x1 @cpu(0)>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deepFM.collect_params()['deepfm0_b'].data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[ 0. -0.  0. ... -0. -0. -0.]\n",
       " [ 0. -0. -0. ...  0.  0.  0.]\n",
       " [-0. -0.  0. ... -0. -0. -0.]\n",
       " ...\n",
       " [ 0. -0. -0. ... -0. -0. -0.]\n",
       " [ 0.  0. -0. ...  0.  0.  0.]\n",
       " [ 0. -0.  0. ...  0.  0.  0.]]\n",
       "<NDArray 200x20 @cpu(0)>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deepFM.collect_params()['dense0_weight'].data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[-0.0000000e+00  0.0000000e+00 -0.0000000e+00  0.0000000e+00\n",
       "  0.0000000e+00  0.0000000e+00  0.0000000e+00 -0.0000000e+00\n",
       " -0.0000000e+00 -0.0000000e+00 -0.0000000e+00  0.0000000e+00\n",
       "  0.0000000e+00  0.0000000e+00 -0.0000000e+00 -0.0000000e+00\n",
       " -0.0000000e+00 -0.0000000e+00  0.0000000e+00 -0.0000000e+00\n",
       "  0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00\n",
       " -0.0000000e+00  0.0000000e+00  0.0000000e+00 -0.0000000e+00\n",
       "  0.0000000e+00 -0.0000000e+00  0.0000000e+00 -0.0000000e+00\n",
       "  0.0000000e+00 -0.0000000e+00 -0.0000000e+00 -3.3192331e-04\n",
       "  0.0000000e+00 -5.5271994e-06 -0.0000000e+00 -0.0000000e+00\n",
       "  0.0000000e+00 -0.0000000e+00 -0.0000000e+00 -0.0000000e+00\n",
       "  0.0000000e+00 -0.0000000e+00 -0.0000000e+00  0.0000000e+00\n",
       "  0.0000000e+00 -0.0000000e+00 -0.0000000e+00  0.0000000e+00\n",
       "  0.0000000e+00 -0.0000000e+00  0.0000000e+00  0.0000000e+00\n",
       "  0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00\n",
       " -0.0000000e+00 -0.0000000e+00  0.0000000e+00 -0.0000000e+00\n",
       "  8.5694285e-04  0.0000000e+00  0.0000000e+00 -0.0000000e+00\n",
       " -0.0000000e+00  0.0000000e+00 -0.0000000e+00  0.0000000e+00\n",
       " -0.0000000e+00  0.0000000e+00  0.0000000e+00 -0.0000000e+00\n",
       "  0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00\n",
       " -0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00\n",
       " -0.0000000e+00 -0.0000000e+00  0.0000000e+00 -0.0000000e+00\n",
       "  0.0000000e+00 -0.0000000e+00  0.0000000e+00  0.0000000e+00\n",
       " -0.0000000e+00  0.0000000e+00 -0.0000000e+00  0.0000000e+00\n",
       "  0.0000000e+00  0.0000000e+00 -0.0000000e+00 -0.0000000e+00\n",
       "  0.0000000e+00 -0.0000000e+00 -0.0000000e+00  0.0000000e+00\n",
       "  0.0000000e+00  0.0000000e+00 -0.0000000e+00  0.0000000e+00\n",
       " -0.0000000e+00 -0.0000000e+00 -0.0000000e+00  0.0000000e+00\n",
       "  0.0000000e+00 -0.0000000e+00 -0.0000000e+00 -0.0000000e+00\n",
       " -0.0000000e+00 -0.0000000e+00  0.0000000e+00  0.0000000e+00\n",
       " -0.0000000e+00 -0.0000000e+00  0.0000000e+00 -0.0000000e+00\n",
       "  0.0000000e+00 -0.0000000e+00  0.0000000e+00  0.0000000e+00\n",
       " -0.0000000e+00 -0.0000000e+00  0.0000000e+00  2.7409940e-05\n",
       "  0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00\n",
       " -0.0000000e+00  0.0000000e+00 -0.0000000e+00 -0.0000000e+00\n",
       " -0.0000000e+00 -0.0000000e+00  0.0000000e+00  0.0000000e+00\n",
       " -0.0000000e+00 -0.0000000e+00 -0.0000000e+00 -0.0000000e+00\n",
       " -0.0000000e+00 -0.0000000e+00 -0.0000000e+00 -0.0000000e+00\n",
       "  0.0000000e+00  0.0000000e+00 -0.0000000e+00 -0.0000000e+00\n",
       " -0.0000000e+00  0.0000000e+00  0.0000000e+00 -0.0000000e+00\n",
       "  0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00\n",
       "  0.0000000e+00  0.0000000e+00 -0.0000000e+00  0.0000000e+00\n",
       " -0.0000000e+00 -0.0000000e+00  0.0000000e+00 -0.0000000e+00\n",
       "  0.0000000e+00  0.0000000e+00 -0.0000000e+00 -0.0000000e+00\n",
       "  0.0000000e+00 -0.0000000e+00 -0.0000000e+00  0.0000000e+00\n",
       " -0.0000000e+00 -0.0000000e+00 -0.0000000e+00  0.0000000e+00\n",
       " -0.0000000e+00  0.0000000e+00 -0.0000000e+00  0.0000000e+00\n",
       " -0.0000000e+00  0.0000000e+00 -0.0000000e+00  0.0000000e+00\n",
       " -0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00\n",
       "  0.0000000e+00 -0.0000000e+00  0.0000000e+00  0.0000000e+00]\n",
       "<NDArray 200 @cpu(0)>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deepFM.collect_params()['dense0_bias'].data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py36",
   "language": "python",
   "name": "py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
